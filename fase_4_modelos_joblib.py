# -*- coding: utf-8 -*-
"""Fase_4_modelos_joblib.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wx9ai3gp7R03ANeDOrB2cOb_MZKMWAGG

##Importando as Bibliotecas
"""

# Importando as bibliotecas
import pandas as pd
import numpy as np

# Matplotlib e seaborn serão usadas para visualização dos dados.
import matplotlib.pyplot as plt
import seaborn as sns

# Scikit-learn será usado para avaliar acurácia e erro dos modelos.
from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer
#from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

from sklearn.model_selection import GridSearchCV

from sklearn.ensemble import RandomForestRegressor
from sklearn.pipeline import make_pipeline

import xgboost as xgb

import warnings
warnings.filterwarnings("ignore")

"""##Aquisição dos Dados

"""

#Obtendo os dados, transformando a coluna de data para formato padrão
df = pd.read_csv('Dados_Ibovespa_jan15_nov25.csv', parse_dates=['Data'], dayfirst=True)
df.rename(columns={'Data' : 'ds', 'Último': 'fechamento', 'Abertura': 'abertura', 'Máxima': 'max', 'Mínima': 'min', 'Vol.':'vol', 'Var%': 'var'}, inplace=True)
df.drop(columns={'var', 'vol'}, inplace=True)
df.head()

#ordenamos os valores em tempo crescente, nosso df inicial estava decrescente.
#Assim, poderemos aplicar a função diff() para calcular a diferençã entre a linha atual e a linha anterior, obtendo assim, a tendência.
df = df.sort_values(by='ds', ascending=True).reset_index(drop=True)
df['y']= df['fechamento'].diff().apply(lambda x: 1 if x > 0 else (-1 if x < 0 else 0))
df.head()

"""Verificação de sazonalidade, teste ADF e verificação de diferenciação realizados no notebook Fase 2.

##Inclusão de novas features e diferenciação dos dados do DataFrame
"""

df['amplitude']=df['max']-df['min']
df['delta']=df['fechamento']-df['abertura']
df['variacao']=df['delta']/df['abertura']

df['volatilidadeS'] = df['delta'].rolling(window=5).std()
df['volatilidadeM'] = df['delta'].rolling(window=22).std()
df['volatilidadeT'] = df['delta'].rolling(window=66).std()
df['volatilidadeSE'] = df['delta'].rolling(window=132).std()
df['volatilidadeA'] = df['delta'].rolling(window=264).std()

df['maS']=df['fechamento'].rolling(window=5).mean()
df['maM']=df['fechamento'].rolling(window=22).mean()
df['maT']=df['fechamento'].rolling(window=66).mean()
df['maSE']=df['fechamento'].rolling(window=132).mean()
df['maA']=df['fechamento'].rolling(window=264).mean()

df.head()

# Realizar a diferenciação em todas as colunas, exceto 'ds' e 'y'
df_diff = df.copy()
cols_to_diff = [col for col in df_diff.columns if col not in ['ds', 'y']]
df_diff[cols_to_diff] = df_diff[cols_to_diff].diff()

df_diff = df_diff.dropna()

# Reordenar as colunas para ter 'ds' e 'y' no início
cols = ['ds', 'y'] + [col for col in df_diff.columns if col not in ['ds', 'y']]
df_diff = df_diff[cols]

df_diff.reset_index(drop=True, inplace=True)
df_diff.head()

"""##Criando funções para métricas de avaliação dos modelos"""

#Função WMAPE para cálculo do erro percentual absoluto através de pesos - Weighted Mean Absloute Percentage Error
def wmape(y_true, y_pred):
  return np.abs(y_true-y_pred).sum()/ np.abs(y_true).sum()

#função para calcular a acuracia direcional

def calcular_acuracia_direcional(df, col_data='ds', col_real='y_test', col_previsto='y_pred'):
#Parâmetros:
#     - df (pd.DataFrame): DataFrame contendo as colunas de data, valor real e valor previsto.
#     - col_data (str): Nome da coluna de datas.
#     - col_real (str): Nome da coluna com os valores reais.
#     - col_previsto (str): Nome da coluna com os valores previstos.

    df = df.sort_values(by=col_data).reset_index(drop=True)

    df['direcao_real'] = np.sign(df[col_real] - df[col_real].shift(1)) #compara valor real do dia com valor real do dia anterior
    df['direcao_prevista'] = np.sign(df[col_previsto] - df[col_previsto].shift(1)) #compara valor previsto do dia com valor previsto para o dia anterior

    df_filtrado = df.dropna()
#   df_filtrado = df_filtrado[df_filtrado['direcao_real'] != 0]

    if not df_filtrado.empty:
        acuracia = accuracy_score(df_filtrado['direcao_real'], df_filtrado['direcao_prevista'])
        return acuracia
    else:
        return np.nan

"""##Previsões com Modelos utilizando Feature Lagged (d-n) -- n=1

Podemos utilizar o valor de hoje para prever amanhã -- features:

d = fechamento, abertura, max, min
d+1 = desejamos descobrir o fechamento
Utilizaremos as features deslocadas (d-1). Sempre se referindo ao dia anterior, com exceção da abertura - esta feature já sabemos no início do dia, pois ela corresponde ao fechamento d-1

y --> variável target
fechamento, abertura, max, min deslocadas de d-1 serão nossas features
"""

# Incluir features defasadas (lagged features) nos dataframes
df_lagged=df_diff.copy()
n_lags = 1 # Número de dias anteriores a serem incluídos como features

# Criar features defasadas para todas as colunas relevantes
#Não iremos defasar a abertura, pois já temos este dado no início do dia. Ele é valor de fechamento do dia anterior.
for col in ['y', 'fechamento', 'max', 'min', 'amplitude', 'delta', 'variacao', 'volatilidadeS', 'volatilidadeM', 'volatilidadeT', 'volatilidadeSE', 'volatilidadeA', 'maS', 'maM', 'maT', 'maSE', 'maA']:
    for i in range(1, n_lags + 1):
        df_lagged[f'{col}_lag_{i}'] = df_lagged[col].shift(i)

df_lagged.dropna(inplace=True)
df_lagged.head()

"""Agora, retiraremos as colunas 'max', 'min', 'amplitude', 'delta', 'variacao', 'volatilidade (todas)', 'ma (todas)' que não foram defasadas. Assim, poderemos prever o dia de hoje, com base no dia de ontem. A coluna abertura, não iremos defasar, pois no início do dia, temos o valor de abertura."""

df_lagged.drop(columns=['max', 'min', 'amplitude', 'delta', 'variacao', 'volatilidadeS', 'volatilidadeM', 'volatilidadeT', 'volatilidadeSE', 'volatilidadeA', 'maS', 'maM', 'maT', 'maSE', 'maA'], inplace=True)
df_lagged.head()

"""##Teste dos Modelos

Para os modelos de regressão, classificaremos a partir da coluna 'fechamento' e em seguida, verificaremos a acurácia direcional comparando com o real.
Determinando a janela temporal de treino e teste
Escolhemos o último mês, conforme orientações do desafio 2.
"""

treino = df_lagged.loc[(df_lagged['ds'] >= '2022-01-01') & (df_lagged['ds'] < '2025-11-03')]
teste = df_lagged.loc[(df_lagged['ds'] >= '2025-11-03') & (df_lagged['ds'] <= '2025-12-01')]

#Determinando análise com variáveis independentes --> abertura, máxima e mínima.
#Variável target (y) -> fechamento
X_treino_R = treino.drop(columns=['ds','fechamento', 'y'])
y_treino_R = treino['fechamento']

X_teste_R = teste.drop(columns=['ds','fechamento', 'y'])
y_teste_R = teste['fechamento']

print('X_treino:', X_treino_R.shape)
print('X_teste:', X_teste_R.shape)
print('y_treino:', y_treino_R.shape)
print('y_teste:', y_teste_R.shape)

"""## Random Forest Regressor"""

print("--- Random Forest Regressor ---")
model = RandomForestRegressor(random_state=42)
model.fit(X_treino_R, y_treino_R)
y_pred_RFR = model.predict(X_teste_R)

print('Métricas de Erro do Modelo Random Forest\n')

mse_RFR = mean_squared_error(y_teste_R, y_pred_RFR)
rmse_RFR = np.sqrt(mse_RFR)
r2_RFR = r2_score(y_teste_R, y_pred_RFR)
mae_RFR = mean_absolute_error(y_teste_R, y_pred_RFR)
mape_RFR = mean_absolute_percentage_error(y_teste_R, y_pred_RFR)
wmape_RFR = wmape(y_teste_R, y_pred_RFR)

print(f'Erro Quadrático Médio (MSE): {mse_RFR:.3f}')
print(f'Raiz do Erro Quadrático Médio (RMSE): {rmse_RFR:.3f}')
print(f'R² Score: {r2_RFR:.3f}')
print(f'Erro Médio Absoluto (MAE): {mae_RFR:.3f}')
print(f'Erro Percentual Absoluto Médio (MAPE): {mape_RFR:.2%}')
print(f'Weighted Mean Absloute Percentage Error (WMAPE): {wmape_RFR:.2%}')

results_df_RFR = pd.DataFrame({'ds': teste['ds'], 'y_teste': y_teste_R, 'y_pred': y_pred_RFR})
results_df_RFR = results_df_RFR.sort_values(by='ds').reset_index(drop=True)
acuracia_RFR = calcular_acuracia_direcional(results_df_RFR, col_data='ds', col_real='y_teste', col_previsto='y_pred')
print(f"\nRandom Forest Regressor Directional Accuracy: {acuracia_RFR:.2%}")

# Visualizando a comparação entre valores reais e previstos para o modelo Random Forest Regressor
plt.figure(figsize=(14, 7))
plt.plot(results_df_RFR['ds'], results_df_RFR['y_teste'], label='Valor Real', marker='o', linestyle='-', markersize=4)
plt.plot(results_df_RFR['ds'], results_df_RFR['y_pred'], label='Valor Previsto (RFR)', marker='x', linestyle='--', markersize=4)

plt.xlabel('Data')
plt.ylabel('Valor de Fechamento')
plt.title('Comparação Real vs. Previsto (Random Forest Regressor)')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

"""##Gradient Boosting - XG Boost"""

print("--- XG Boost ---")

modelo = xgb.XGBRegressor( objective='reg:squarederror',
    colsample_bytree=1,
    learning_rate=0.9,
    max_depth=3,
    alpha=10,
    n_estimators=100,
    random_state=42
)

modelo.fit(X_treino_R, y_treino_R)
y_pred_XGB = modelo.predict(X_teste_R)

print('Métricas de Erro do Modelo XGBoost\n')

mse_XGB = mean_squared_error(y_teste_R, y_pred_XGB)
rmse_XGB = np.sqrt(mse_XGB)
r2_XGB = r2_score(y_teste_R, y_pred_XGB)
mae_XGB = mean_absolute_error(y_teste_R, y_pred_XGB)
mape_XGB = mean_absolute_percentage_error(y_teste_R, y_pred_XGB)
wmape_XGB = wmape(y_teste_R, y_pred_XGB)

print(f'Erro Quadrático Médio (MSE): {mse_XGB:.3f}')
print(f'Raiz do Erro Quadrático Médio (RMSE): {rmse_XGB:.3f}')
print(f'R² Score: {r2_XGB:.3f}')
print(f'Erro Médio Absoluto (MAE): {mae_XGB:.3f}')
print(f'Erro Percentual Absoluto Médio (MAPE): {mape_XGB:.2%}')
print(f'Weighted Mean Absloute Percentage Error (WMAPE): {wmape_XGB:.2%}')

results_df_XGB = pd.DataFrame({'ds': teste['ds'], 'y_teste': y_teste_R, 'y_pred': y_pred_XGB})
results_df_XGB = results_df_XGB.reset_index(drop=True)
acuracia_XGB = calcular_acuracia_direcional(results_df_XGB, col_data='ds', col_real='y_teste', col_previsto='y_pred')
print(f"\nXG Boost Directional Accuracy: {acuracia_XGB:.2%}")

# Visualizando a comparação entre valores reais e previstos para o modelo XGBoost
plt.figure(figsize=(14, 7))
plt.plot(results_df_XGB['ds'], results_df_XGB['y_teste'], label='Valor Real', marker='o', linestyle='-', markersize=4)
plt.plot(results_df_XGB['ds'], results_df_XGB['y_pred'], label='Valor Previsto (XGB)', marker='x', linestyle='--', markersize=4)

plt.xlabel('Data')
plt.ylabel('Valor de Fechamento')
plt.title('Comparação Real vs. Previsto (XG Boost)')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

"""##JobLib"""

import joblib

joblib.dump(model, 'modelo_RFR.joblib')

joblib.dump(modelo, 'modelo_XGB.joblib')

